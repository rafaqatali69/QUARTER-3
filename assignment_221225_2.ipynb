{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOaQJEAYQ2JvFuUjefwgd0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaqatali69/QUARTER-3/blob/main/assignment_221225_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA9q5FVCHRYa"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY:str=userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "4dnbBSOAIKol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if('GEMINI_API_KEY'):\n",
        "    print(\"KEY FOUND\")\n",
        "else:\n",
        "  print(\"KEY NOT FOUND\")"
      ],
      "metadata": {
        "id": "9jSaDPLrJPGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import client\n",
        "client:client=genai.Client(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "TeEDvYkMLktd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model:str=\"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "YUp1FmzlL2Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([attr for attr in dir(client) if not attr.startswith('_')])\n",
        "print([attr for attr in dir(client.models) if not attr.startswith('_')])"
      ],
      "metadata": {
        "id": "JwGug2raPiNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import GenerateContentResponse\n",
        "from IPython.display import display, Markdown\n",
        "Response: GenerateContentResponse = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents='how does AI work'\n",
        ")\n",
        "generated_text = Response.text\n",
        "display(Markdown(Response.text))"
      ],
      "metadata": {
        "id": "YlVfKoRSSgHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COUNT TOKEN\n",
        "from google.genai.types import CountTokensResponse\n",
        "Result: CountTokensResponse = client.models.count_tokens(\n",
        "    model=model,\n",
        "    contents='whats the hightest mountain in the worldhow does AI work'\n",
        ")\n",
        "print(Result)"
      ],
      "metadata": {
        "id": "Zd9Swkw9daHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE PROMPT AND RESPONSE\n",
        "!curl -o image.jpg \"https://i.dawn.com/primary/2014/07/53d4ba719c131.jpg\""
      ],
      "metadata": {
        "id": "RVTh9UOIfe4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as img\n",
        "img_k2 = img.open('/content/image.jpg')\n",
        "display(img_k2)"
      ],
      "metadata": {
        "id": "ZN4x-_36g2-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\"\"\"the brief notes of this mountain. Features: History, Name the persons who submit it in winter \"\"\")"
      ],
      "metadata": {
        "id": "rkeuVNbTiSZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Response: GenerateContentResponse = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=[img_k2,prompt]\n",
        ")\n",
        "display(Markdown(Response.text))"
      ],
      "metadata": {
        "id": "SxHUDFuJifo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHAT MODEL\n",
        "response: GenerateContentResponse = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents='Pleaes Note, My name is Rafaqat ALI'\n",
        ")\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "KeEbVy7wdkF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response: GenerateContentResponse = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents='What is my name'\n",
        ")\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "7ohitdRRk06T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.chats import Chat\n",
        "chat: Chat = client.chats.create(\n",
        "    model=model\n",
        ")\n",
        "response: GenerateContentResponse = chat.send_message(\"My name is Rafaqat Ali\")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "uEtN2NfMlCkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response: GenerateContentResponse = chat.send_message(\"What is my name?\")\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "gns3UM3Vlk0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HOW LLM UNDERSTAND VIDEO\n"
      ],
      "metadata": {
        "id": "izbgSBe9l50d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sample images\n",
        "#!wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n",
        "#!wget https://youtu.be/WCTa9HGcFg0?si=J9gZB9HC29peFjBY -O Pottery -q\n",
        "!wget /content/wallclimbing.mp4 -q\n"
      ],
      "metadata": {
        "id": "Jt1cMdkjm11g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the videos using the File API.\n",
        "# find more details about how to use in the Get Started notebook.\n",
        "# Take couple of minutes because the videos need to be processed and tokenized.\n",
        "\n",
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path=video_file_name)\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting video is Processing.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name or \"\")\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "\n",
        "  return video_file\n",
        "\n",
        "#pottery_video = upload_video('Pottery.mp4')\n",
        "pottery_video = upload_video('wallclimbing.mp4')"
      ],
      "metadata": {
        "id": "Hftlp88QpRPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import Content, Part\n",
        "prompt = \"\"\"For each scene in this video,\n",
        "            please generate captions that describe the scene along with any spoken text placed in quotation marks.\n",
        "            Place each caption into an object with the timecode of the caption in the video.\n",
        "         \"\"\"\n",
        "\n",
        "video = pottery_video\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_uri(\n",
        "                    file_uri=video.uri or \"\",\n",
        "                    mime_type=video.mime_type or \"\"),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "qaDYRGB6sanb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUDIO TESTING"
      ],
      "metadata": {
        "id": "GycdzvuFvs--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    http_options= {'api_version': 'v1alpha'}\n",
        "  )\n",
        "MODEL = \"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "iT55IN4hvyVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import base64\n",
        "import contextlib\n",
        "import datetime\n",
        "import os\n",
        "import json\n",
        "import wave\n",
        "import itertools\n",
        "\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "async def async_enumerate(it):\n",
        "  n = 0\n",
        "  async for item in it:\n",
        "    yield n, item\n",
        "    n +=1"
      ],
      "metadata": {
        "id": "TUJvlXOTwHZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@contextlib.contextmanager\n",
        "def wave_file(filename, channels=1, rate=24000, sample_width=2):\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        yield wf"
      ],
      "metadata": {
        "id": "tUA1lIRTwjSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config={\n",
        "    \"generation_config\": {\"response_modalities\": [\"AUDIO\"]}}\n",
        "\n",
        "async with client.aio.live.connect(model=MODEL, config=config) as session:\n",
        "  file_name = 'audio.wav'\n",
        "  with wave_file(file_name) as wav:\n",
        "    message = \"Hello? Gemini, What you know about k-2 mountain?\"\n",
        "    print(\"> \", message, \"\\n\")\n",
        "    await session.send(message, end_of_turn=True)\n",
        "\n",
        "    turn = session.receive()\n",
        "    async for n,response in async_enumerate(turn):\n",
        "      if response.data is not None:\n",
        "        wav.writeframes(response.data)\n",
        "\n",
        "        if n==0:\n",
        "          print(response.server_content.model_turn.parts[0].inline_data.mime_type)\n",
        "        print('.', end='')\n",
        "\n",
        "\n",
        "display(Audio(file_name, autoplay=True))"
      ],
      "metadata": {
        "id": "7el6xXtgw-O2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}