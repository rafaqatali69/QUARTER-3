{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP0wxLGNwtTf7a433cS7gZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaqatali69/QUARTER-3/blob/main/assignment_221224_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VLIq0E5C0ixK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet google-genai\n",
        "!pip install langchain\n",
        "!pip install --upgrade --quiet LangChain\n",
        "!pip install langchain_google_genai\n",
        "!pip install --upgrade --quiet langchain_google_genai\n"
      ],
      "metadata": {
        "id": "4UmuaGeP0meY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n"
      ],
      "metadata": {
        "id": "XnSAaXXa2S_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "#llm = ChatVertexAI(\n",
        "    api_key='GOOGLE_API_KEY',\n",
        "    model = \"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7 # Adjust for creativity\n",
        ")"
      ],
      "metadata": {
        "id": "VLNPAq8wnNC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are a helpful assistant. Answer the following question:\\n\\n{question}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "CLgf1rSyaZVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "iyGUXTy9qFTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain with a sample question\n",
        "question = \"What is LangChain?\""
      ],
      "metadata": {
        "id": "-MFEkkNNsGmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run({\"question\": question})\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "laDYvZWus2c8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}